import streamlit as st
import json
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import PromptTemplate
from langchain.output_parsers import PydanticOutputParser
from langchain.chains import LLMChain
from pydantic import BaseModel, RootModel
from typing import List
from modules.DB import SupabaseDB

# 1. Supabaseì—ì„œ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
db = SupabaseDB()
id_lst = db.get_all_user_id()
articles = db.get_article_data_today()

# 2. Gemini LLM ì„¤ì •
api_key = st.secrets["gemini"]["api_key"]
llm = ChatGoogleGenerativeAI(
    model="gemini-2.0-flash",
    temperature=0,
    google_api_key=api_key
)


# 3. Pydantic ìŠ¤í‚¤ë§ˆ ì •ì˜
class NewsItem(BaseModel):
    title: str
    url: str
    reason: str


class NewsList(RootModel[List[NewsItem]]):
    pass


parser = PydanticOutputParser(pydantic_object=NewsList)
format_instructions = parser.get_format_instructions()

# 4. í”„ë¡¬í”„íŠ¸ êµ¬ì„± (ì •êµí•œ ë‰´ìŠ¤ ì¶”ì²œ ìœ ë„)
prompt_template = PromptTemplate(
    input_variables=["keywords", "articles", "format_instructions"],
    template="""
    ë‹¹ì‹ ì€ ê¸ˆìœµ ë¶„ì•¼ì— íŠ¹í™”ëœ ë‰´ìŠ¤ ì¶”ì²œ AIì…ë‹ˆë‹¤.

    ë‹¤ìŒì€ ì‚¬ìš©ìê°€ í˜„ì¬ ë³´ìœ  ì¤‘ì¸ ìì‚° í‚¤ì›Œë“œì…ë‹ˆë‹¤:
    {keywords}

    ê·¸ë¦¬ê³  ë‹¤ìŒì€ ì˜¤ëŠ˜ ìˆ˜ì§‘ëœ ì£¼ìš” ê²½ì œ ë‰´ìŠ¤ ê¸°ì‚¬ì…ë‹ˆë‹¤:
    {articles}

    ì´ ì¤‘ì—ì„œ ì•„ë˜ ì¡°ê±´ì„ ê°€ì¥ ì˜ ì¶©ì¡±í•˜ëŠ” ìƒìœ„ 3ê°œì˜ ë‰´ìŠ¤ë¥¼ ì„ ì •í•´ ì£¼ì„¸ìš”:

    1. ë‰´ìŠ¤ ì œëª© ë˜ëŠ” ë³¸ë¬¸ ë‚´ìš©ì´ ìì‚° í‚¤ì›Œë“œ(ì˜ˆ: ì¢…ëª©ëª…, ì‚°ì—…êµ°, ETF ë“±)ì™€ ì§ì ‘ì ìœ¼ë¡œ ì—°ê´€ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
    2. í•´ë‹¹ ë‰´ìŠ¤ê°€ ì‚¬ìš©ìì˜ ìì‚° ê°€ì¹˜ì— ê¸ì •ì  ë˜ëŠ” ë¶€ì •ì  ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆëŠ” ë‚´ìš©ì¼ìˆ˜ë¡ ìš°ì„ ì ìœ¼ë¡œ ì„ íƒí•©ë‹ˆë‹¤.
    3. ë‰´ìŠ¤ ê°„ ì¤‘ë³µì„±ì´ ì—†ë„ë¡ í•˜ë©°, ë‹¤ì–‘í•œ ìì‚°ê³¼ ì—°ê´€ëœ ê¸°ì‚¬ë¥¼ ì„ ë³„í•©ë‹ˆë‹¤.

    ê° ë‰´ìŠ¤ì— ëŒ€í•´ ì•„ë˜ JSON í˜•ì‹ì— ë§ê²Œ, ê°„ê²°í•˜ê³  ëª…í™•í•œ ê´€ë ¨ ì´ìœ ë¥¼ í¬í•¨í•˜ì—¬ ì¶œë ¥í•˜ì„¸ìš”.

    â—ì£¼ì˜: ë°˜ë“œì‹œ JSON í˜•ì‹ë§Œ ì¶œë ¥í•˜ì„¸ìš”. í•´ì„¤, ì„¤ëª…, ë§ˆí¬ë‹¤ìš´ ë“±ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.

    {format_instructions}
    """
)

# 5. LangChain ì²´ì¸ êµ¬ì„±
chain = LLMChain(
    llm=llm,
    prompt=prompt_template
)

for user_id in id_lst:
    stocks = db.get_stock_data(user_id)

    # 6. ì…ë ¥ êµ¬ì„±
    user_keywords = [stock["ìƒí’ˆëª…"] for stock in stocks]
    formatted_articles = "\n".join([f"- {a['title']} ({a['url']})" for a in articles])

    # 7. LLM í˜¸ì¶œ ë° íŒŒì‹±
    try:
        raw_output = chain.run({
            "keywords": ", ".join(user_keywords),
            "articles": formatted_articles,
            "format_instructions": format_instructions
        })

        result = parser.parse(raw_output)
        response = result.root  # List[NewsItem]

    except Exception as e:
        st.error(f"âŒ ëª¨ë¸ ì‹¤í–‰ ë˜ëŠ” íŒŒì‹± ì˜¤ë¥˜ ë°œìƒ: {e}")
        st.code(raw_output if 'raw_output' in locals() else "ëª¨ë¸ ì‘ë‹µ ì—†ìŒ")
        response = None

    # 8. ê²°ê³¼ ì¶œë ¥
    if response:
        # st.subheader("ğŸ” ê´€ì‹¬ ì¢…ëª© ê´€ë ¨ ë‰´ìŠ¤ ì¶”ì²œ Top 3")
        # for item in response:
        #     st.markdown(f"### [{item.title}]({item.url})")
        #     st.markdown(f"- ğŸ“Œ ê´€ë ¨ ì´ìœ : {item.reason}")

        # 9. Supabaseì— ì¶”ì²œ ë‰´ìŠ¤ JSON ì €ì¥
        # user_id = st.session_state.get("id", "anonymous")
        json_articles = [{"title": item.title, "url": item.url} for item in response]

        try:
            db.insert_recommended_articles(user_id, json_articles)
            st.success("âœ… ì¶”ì²œ ë‰´ìŠ¤ê°€ Supabaseì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.warning(f"âš ï¸ Supabase ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

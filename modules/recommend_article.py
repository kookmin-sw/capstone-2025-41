from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import PromptTemplate
from langchain.output_parsers import PydanticOutputParser
from langchain.chains import LLMChain
from pydantic import BaseModel, RootModel
from typing import List
from DB import SupabaseDB
from dotenv import load_dotenv
import os
import streamlit as st

# .env íŒŒì¼ì˜ í™˜ê²½ ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°
load_dotenv()

# 1. Supabaseì—ì„œ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
db = SupabaseDB()
id_lst = db.get_all_user_id()
articles = db.get_article_data_today_and_yesterday()

# 2. Gemini LLM ì„¤ì •
api_key = os.getenv("GEMINI_KEY")
llm = ChatGoogleGenerativeAI(
    model="gemini-2.0-flash",
    temperature=0,
    google_api_key=api_key
)

# 3. Pydantic ìŠ¤í‚¤ë§ˆ ì •ì˜
class NewsItem(BaseModel):
    title: str
    url: str
    reason: str
    summary: str  # ë³¸ë¬¸ ìš”ì•½ ì¶”ê°€

class NewsList(RootModel[List[NewsItem]]):
    pass

parser = PydanticOutputParser(pydantic_object=NewsList)
format_instructions = parser.get_format_instructions()

# 4. í”„ë¡¬í”„íŠ¸ êµ¬ì„± (ì •êµí•œ ë‰´ìŠ¤ ì¶”ì²œ ìœ ë„)
prompt_template = PromptTemplate(
    input_variables=["keywords", "articles", "format_instructions"],
    template="""
    ë‹¹ì‹ ì€ ê¸ˆìœµ ë¶„ì•¼ì— íŠ¹í™”ëœ ë‰´ìŠ¤ ì¶”ì²œ AIì…ë‹ˆë‹¤.

    ë‹¤ìŒì€ ì‚¬ìš©ìê°€ í˜„ì¬ ë³´ìœ  ì¤‘ì¸ ìì‚° í‚¤ì›Œë“œì…ë‹ˆë‹¤:
    {keywords}

    ê·¸ë¦¬ê³  ë‹¤ìŒì€ ì˜¤ëŠ˜ ìˆ˜ì§‘ëœ ì£¼ìš” ê²½ì œ ë‰´ìŠ¤ ê¸°ì‚¬ì…ë‹ˆë‹¤:
    {articles}

    ì´ ì¤‘ì—ì„œ ì•„ë˜ ì¡°ê±´ì„ ê°€ì¥ ì˜ ì¶©ì¡±í•˜ëŠ” ìƒìœ„ 3ê°œì˜ ë‰´ìŠ¤ë¥¼ ì„ ì •í•´ ì£¼ì„¸ìš”:

    1. ë‰´ìŠ¤ ì œëª© ë˜ëŠ” ë³¸ë¬¸ ë‚´ìš©ì´ ìì‚° í‚¤ì›Œë“œ(ì˜ˆ: ì¢…ëª©ëª…, ì‚°ì—…êµ°, ETF ë“±)ì™€ ì§ì ‘ì ìœ¼ë¡œ ì—°ê´€ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
    2. í•´ë‹¹ ë‰´ìŠ¤ê°€ ì‚¬ìš©ìì˜ ìì‚° ê°€ì¹˜ì— ê¸ì •ì  ë˜ëŠ” ë¶€ì •ì  ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆëŠ” ë‚´ìš©ì¼ìˆ˜ë¡ ìš°ì„ ì ìœ¼ë¡œ ì„ íƒí•©ë‹ˆë‹¤.
    3. ë‰´ìŠ¤ ê°„ ì¤‘ë³µì„±ì´ ì—†ë„ë¡ í•˜ë©°, ë‹¤ì–‘í•œ ìì‚°ê³¼ ì—°ê´€ëœ ê¸°ì‚¬ë¥¼ ì„ ë³„í•©ë‹ˆë‹¤.

    ê° ë‰´ìŠ¤ì— ëŒ€í•´ ì•„ë˜ JSON í˜•ì‹ì— ë§ê²Œ, ê°„ê²°í•˜ê³  ëª…í™•í•œ ê´€ë ¨ ì´ìœ ì™€ ë³¸ë¬¸ ìš”ì•½ì„ í¬í•¨í•˜ì—¬ ì¶œë ¥í•˜ì„¸ìš”.

    - title: ë‰´ìŠ¤ ì œëª©
    - url: ë‰´ìŠ¤ ë§í¬
    - reason: ì¶”ì²œ ì´ìœ  (ì‚¬ìš©ìì˜ ìì‚°ê³¼ ê´€ë ¨ëœ ê°„ë‹¨í•œ ì„¤ëª…)
    - summary: ë‰´ìŠ¤ ë³¸ë¬¸ ìš”ì•½ (3ì¤„ ì´ë‚´)

    â—ì£¼ì˜: ë°˜ë“œì‹œ JSON í˜•ì‹ë§Œ ì¶œë ¥í•˜ì„¸ìš”. í•´ì„¤, ì„¤ëª…, ë§ˆí¬ë‹¤ìš´ ë“±ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.

    {format_instructions}
    """
)

# 5. LangChain ì²´ì¸ êµ¬ì„±
chain = LLMChain(
    llm=llm,
    prompt=prompt_template
)

# 6. ì‚¬ìš©ìë³„ ë‰´ìŠ¤ ì¶”ì²œ ìˆ˜í–‰
for user_id in id_lst:
    stocks = db.get_stock_data(user_id)

    # ìì‚° í‚¤ì›Œë“œì™€ ê¸°ì‚¬ ë³¸ë¬¸ í¬í•¨ êµ¬ì„±
    user_keywords = [stock["ìƒí’ˆëª…"] for stock in stocks]
    formatted_articles = "\n".join([
        f"- {a['title']}: {a['main']} ({a['url']})"
        for a in articles
    ])

    # 7. LLM í˜¸ì¶œ ë° íŒŒì‹±
    try:
        raw_output = chain.run({
            "keywords": ", ".join(user_keywords),
            "articles": formatted_articles,
            "format_instructions": format_instructions
        })

        result = parser.parse(raw_output)
        response = result.root  # List[NewsItem]

    except Exception as e:
        print(f"âŒ ëª¨ë¸ ì‹¤í–‰ ë˜ëŠ” íŒŒì‹± ì˜¤ë¥˜ ë°œìƒ: {e}")
        print(raw_output if 'raw_output' in locals() else "ëª¨ë¸ ì‘ë‹µ ì—†ìŒ")
        response = None

    # 8. ê²°ê³¼ ì €ì¥
    if response:
        json_articles = [
            {
                "title": item.title,
                "url": item.url,
                "reason": item.reason,
                "summary": item.summary
            }
            for item in response
        ]

        try:
            db.insert_recommended_articles(user_id, json_articles)
            print(f"âœ… ì¶”ì²œ ë‰´ìŠ¤ê°€ ì‚¬ìš©ì {user_id}ì— ëŒ€í•´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"âš ï¸ Supabase ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

        # st.subheader(f"ğŸ” ì‚¬ìš©ì {user_id} ì¶”ì²œ ë‰´ìŠ¤ Top 3")
        # for idx, item in enumerate(response, 1):
        #     with st.container():
        #         st.markdown(f"### {idx}. {item.title}")
        #         st.markdown(f"ğŸ“Œ **ì¶”ì²œ ì´ìœ **: {item.reason}")
        #         st.markdown(f"ğŸ“ **ë³¸ë¬¸ ìš”ì•½**: {item.summary}")
        #         st.markdown(f"ğŸ”— [ê¸°ì‚¬ ë§í¬ ë³´ê¸°]({item.url})", unsafe_allow_html=True)
        #         st.markdown("---")
